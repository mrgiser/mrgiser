<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flux模式开发提交JStorm任务]]></title>
    <url>%2F2017%2F12%2F02%2Fjstormflux%2F</url>
    <content type="text"><![CDATA[传统法式采用提交jar包的方式运行topology，一旦我们需要改变拓扑里头的相应配置，我们就必须重新编译和打包，而Flux可以帮助我们创建和部署jstorm拓扑的编程框架及组件。它可以将你代码中有关topology结构以及提交部分用一句话加上配置文件完成。 传统方式在jar内完成topology的构建以及数据流配置，代码可能如下：1234567891011121314151617TopologyBuilder builder = new TopologyBuilder();builder.setSpout(&quot;send&quot;,new genRandomSentenceSpout());builder.setBolt(&quot;split&quot;,new splitSentenceBolt()).shuffleGrouping(&quot;send&quot;); builder.setBolt(&quot;count&quot;,new wordCountBolt()).fieldsGrouping(&quot;split&quot;,new Fields(&quot;word&quot;));Config conf=new Config();conf.setNumWorkers(1);conf.setNumAckers(1);boolean runLocal = shouldRunLocal();if(runLocal)&#123; LocalCluster cluster = new LocalCluster(); cluster.submitTopology(name, conf, builder.createTopology()); //本地提交&#125; else &#123; StormSubmitter.submitTopology(name, conf, builder.createTopology()); //集群提交 &#125;&#125; 使用Flux，上面代码可用如下Flux命令代替：12jstorm jar mytopology.jar com.alibaba.jstorm.flux.Flux --local config.yaml //本地提交jstorm jar mytopology.jar com.alibaba.jstorm.flux.Flux --remote config.yaml //远程提交 Flux方式开发maven依赖与打包配置由于需要maven依赖flux-core，而flux-core在网上没有链接可以下载，所以需要手动生产安装。通过集群版本下载对应JStorm源码，maven中编译安装JStorm-Flux，会在你本地maven仓库中安装jstorm-core.jar。 然后在开发topology项目中添加maven依赖：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;flux-core&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如下代码以maven-shade打包为例，在pom.xml中添加打包方式，其中mainClass设置为com.alibaba.jstorm.flux.Flux123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot; /&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.alibaba.jstorm.flux.Flux&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 配置文件开发完spout、bolt后不需要在main函数中显示配置topology的结构，采用配置文件的方式来构建topology结构。例如如下的代码跟配置文件在效果上是一样的。1234567891011//代码方式构建topologyTopologyBuilder builder = new TopologyBuilder();builder.setSpout(&quot;send&quot;,new genRandomSentenceSpout());builder.setBolt(&quot;split&quot;,new splitSentenceBolt()).shuffleGrouping(&quot;send&quot;); builder.setBolt(&quot;count&quot;,new wordCountBolt()).fieldsGrouping(&quot;split&quot;,new Fields(&quot;word&quot;));Config conf=new Config();conf.setNumWorkers(1);conf.setNumAckers(1);StormSubmitter. submitTopology(topo_name , conf, builder.createTopology() ); 123456789101112131415161718192021222324252627282930313233343536# Flux配置文件方式---# 定义topology名name: &quot;flux&quot;# topology有关配置，worker、acker数量配置config: topology.workers: 1 topology.ackers: 1# spouts配置spouts: - id: &quot;word-spout&quot; className: &quot;spout.genRandomSentenceSpout&quot;parallelism: 1# Bolt配置bolts: - id: &quot;word-counter&quot; className: &quot;bolt.wordCountBolt&quot; parallelism: 1 - id: &quot;split-bolt&quot; className: &quot;bolt.splitSentenceBolt&quot; parallelism: 1# 数据流配置streams: - name: &quot;word-spout --&gt; split-bolt&quot; # name isn&apos;t used (placeholder for logging, UI, etc.) from: &quot;word-spout&quot; to: &quot;split-bolt&quot; grouping: type: SHUFFLE - name: &quot;split-bolt --&gt; word-counter&quot; from: &quot;split-bolt&quot; to: &quot;word-counter&quot; grouping: type: SHUFFLE args: [&quot;word&quot;] 发布提交一旦你用flux完成了topology打包，你就可以利用配置文件来跑各种拓扑啦。比如你的jar名称为myTopology-0.1.0-SNAPSHOT.jar， 你可以利用以下命令跑本地模式1jstorm jar myTopology-0.1.0-SNAPSHOT.jar com.alibaba.jstorm.flux.Flux --local my_config.yaml 当然你也可以跑分布式模式1jstorm jar myTopology-0.1.0-SNAPSHOT.jar com.alibaba.jstorm.flux.Flux --remote my_config.yaml]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JStorm运行依赖storm-core的任务：依赖冲突与解决]]></title>
    <url>%2F2017%2F11%2F29%2FJStorm%E8%BF%90%E8%A1%8C%E4%BE%9D%E8%B5%96storm-core%E7%9A%84%E4%BB%BB%E5%8A%A1%EF%BC%9A%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81%E4%B8%8E%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[JStorm虽然用Java语言重新实现了storm，但是对于storm的external部分并未实现。现在在JStorm基础上构建topology时，需要使用storm的external部分中的storm-sql-core以及storm-sql-runtime，这样在构建topology的项目中需要同时依赖storm-core、jstorm-core，出现了冲突。 本地调试问题Found multiple defaults.yaml resources根据前面描述的情况，maven的pom.xml文件将包含如下的依赖jstorm-core、storm-core、storm-sql-core、storm-sql-runtime。123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;jstorm-core&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;!--本地调试时注释一下scope --&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-sql-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-sql-runtime&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt; 此时按照JStorm本地调试的模式在ide中运行，12345LocalCluster cluster = new LocalCluster();cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());Utils.sleep(20000);cluster.killTopology(TOPOLOGY_NAME);cluster.shutdown(); 出现如下报错：123456789101112131415161718192021Exception in thread &quot;main&quot; java.lang.ExceptionInInitializerErrorat backtype.storm.topology.BaseConfigurationDeclarer.(BaseConfigurationDeclarer.java:29)at backtype.storm.topology.TopologyBuilder$ConfigGetter.(TopologyBuilder.java:433)at backtype.storm.topology.TopologyBuilder$SpoutGetter.(TopologyBuilder.java:450)at backtype.storm.topology.TopologyBuilder.setSpout(TopologyBuilder.java:289)at com.ctg.itrdc.ruleengine.JsonTopology.main(JsonTopology.java:34)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Caused by: java.lang.RuntimeException: Invalid configuration defaults.yaml:Found multiple defaults.yaml resources. You&apos;re probably bundling the Storm jars with your topology jar. [jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/com/alibaba/jstorm/jstorm-core/2.2.1/jstorm-core-2.2.1.jar!/defaults.yaml, jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/org/apache/storm/storm-core/1.1.1/storm-core-1.1.1.jar!/defaults.yaml]at com.alibaba.jstorm.utils.LoadConf.findAndReadYaml(LoadConf.java:77)at backtype.storm.utils.Utils.readDefaultConfig(Utils.java:355)at backtype.storm.utils.Utils.readStormConfig(Utils.java:453)at backtype.storm.utils.Utils.(Utils.java:112)... 10 moreCaused by: java.io.IOException: Found multiple defaults.yaml resources. You&apos;re probably bundling the Storm jars with your topology jar. [jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/com/alibaba/jstorm/jstorm-core/2.2.1/jstorm-core-2.2.1.jar!/defaults.yaml, jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/org/apache/storm/storm-core/1.1.1/storm-core-1.1.1.jar!/defaults.yaml]at com.alibaba.jstorm.utils.LoadConf.getConfigFileInputStream(LoadConf.java:101)at com.alibaba.jstorm.utils.LoadConf.findAndReadYaml(LoadConf.java:55)... 13 more 可以看出是因为同时依赖了jstorm-core、storm-core导致存在多个配置文件加载出错。 解决方法解决的方法比较暴力，pom.xml文件不需要做修改，保持jstorm-core、storm-core等被注释了，找到冲突的本地maven仓库中的/repository/org/apache/storm/storm-core/1.1.1/storm-core-1.1.1.jar，将jar包下的defaults.yaml删除。采用本地模式提交topology，注意有关提交topology的类，依赖自JStorm中的import backtype.storm.xxx、不要继承自import org.apache.storm.xxx。以上，主要是删除storm中有冲突的配置文件defaults.yaml。 集群模式问题问题1:Invalid signature file digest for Manifest main attributes修改pom.xml，将jstorm-core、storm-core设置为provided，修改本地提交代码为集群提交：StormSubmitter. submitTopology(topo_name , config, builder.createTopology() );打包后去集群上执行，提交失败，报错：Exception in thread “main” java.lang.SecurityException: Invalid signature file digest for Manifest main attributes12345678910111213141516171819202122232425262728293031323334353637$ ./jstorm jar ~/topology/ruleengine-0.0.1-SNAPSHOT.jar com.ctg.itrdc.ruleengine.JsonTopology ruleengine2/usr/java/jdk1.8.0_111/bin/javaException in thread &quot;main&quot; java.lang.ExceptionInInitializerError at backtype.storm.command.config_value.main(config_value.java:40)Caused by: java.lang.SecurityException: Invalid signature file digest for Manifest main attributes at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:314) at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:268) at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316) at java.util.jar.JarVerifier.update(JarVerifier.java:228) at java.util.jar.JarFile.initializeVerifier(JarFile.java:383) at java.util.jar.JarFile.getInputStream(JarFile.java:450) at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:940) at sun.misc.Resource.cachedInputStream(Resource.java:77) at sun.misc.Resource.getByteBuffer(Resource.java:160) at java.net.URLClassLoader.defineClass(URLClassLoader.java:454) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at backtype.storm.utils.Utils.&lt;clinit&gt;(Utils.java:103) ... 1 moreFailed to get config java.library.pathNoneruleengine2cannot concatenate &apos;str&apos; and &apos;NoneType&apos; objectsSyntax: [jstorm jar topology-jar-path class ...] Runs the main method of class with the specified arguments. The jstorm jars and configs in $JSTORM_CONF_DIR/storm.yaml are put on the classpath. The process is configured so that StormSubmitter (https://github.com/alibaba/jstorm/wiki/JStorm-Chinese-Documentation) will upload the jar at topology-jar-path when the topology is submitted. 解决方法1谷歌后发现，Exception in thread “main” java.lang.SecurityException: Invalid signature file digest for Manifest main attributes错误是maven打包时设置的问题，修改打包配置如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.ctg.itrdc.ruleengine.JsonTopology&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 主要是添加如下部分。12345678910&lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt;&lt;/filters&gt; 问题 2:storm-core类加载失败按照在Git上的看到的回复，集群运行时，设置依赖的时候jstorm和storm的依赖应该都设置成provided。解决了问题1后，成功提交topology，能够成功运行，在web-UI中查看日志也没有出错，但是topology运行的结果不对。 猜测是storm-sql-core以及storm-sql-runtime依赖了storm-core，但是因为jstorm-core、storm-core设置为provided，但是JStorm集群中只有jstorm-core是provided，而storm-core仍然是没有提供。 坑的是类加载失败错误是直接system.out.print，而不是会打印log，所以在Web-UI中是看不到具体错误的。继续按照猜测走下去，在pom.xml中将storm-core的provided注释掉:1&lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; 打包提交，成功加载了storm-core的类，且topology正常运行没有报错,问题解决。]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何本地调试-JStorm程序]]></title>
    <url>%2F2017%2F11%2F15%2F%E5%A6%82%E4%BD%95%E6%9C%AC%E5%9C%B0%E8%B0%83%E8%AF%95-JStorm-%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[JStorm 提供了两种运行模式：本地模式和分布式模式。本地模式针对开发调试storm topologies非常有用。 如果你还在用日常的web ui提交拓扑这种远古的方式进行调试测试，那就赶快阅读本文吧。本文将介绍在本机不安装JStorm环境的情况下，开发、调试JStorm程序。 单机模式主要是在代码中加入：import backtype.storm.LocalCluster; LocalCluster cluster = new LocalCluster(); //建议加上这行，使得每个bolt/spout的并发度都为1 conf.put(Config.TOPOLOGY_MAX_TASK_PARALLELISM, 1); //提交拓扑 cluster.submitTopology("SequenceTest", conf, builder.createTopology()); //等待1分钟， 1分钟后会停止拓扑和集群， 视调试情况可增大该数值 Thread.sleep(60000); //结束拓扑 cluster.killTopology("SequenceTest"); cluster.shutdown(); 用LocalCluster来模拟集群环境，你可以在LocalCluster对象上调用submitTopology方法来提交拓扑，submitTopology(String topologyName, Map conf, StormTopology topology)接受一个拓扑名称，一个拓扑的配置，以及一个拓扑的对象。就像StormSubmitter一样。你还可以调用killTopology来结束一个拓扑。对应的还有active,deactive,rebalance等方法。由于JStorm是个不会停止的程序，所以我们最后需要显示地停掉集群。 修改pom.xml以jstorm 2.1.1版本为例。 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;jstorm-core&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;!-- keep jstorm out of the jar-with-dependencies --&gt; &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt; &lt;/dependency&gt; 注意要注释掉jstorm依赖中的&lt;scope&gt;provided&lt;/scope&gt;，而提交的时候必须记得将这行改回来！ 否则会报多个defaults.yaml的错误。 注：如果依赖的是 0.9.x 版本的jstorm，会有三个依赖包，将这三个依赖的provided都注释掉。 Re-import 项目， 然后运行main class就可以了。为了更好的代码组织，建议将本地运行和集群运行写成两个方法，根据参数/配置来调用不同的运行方式。更多可以参照SequenceTopology的例子 注意点本地调试主要是用于测试应用逻辑的，因此有一些限制，如classloader是不起作用的。此外，还需要注意一下你的应用中log4j的依赖，如果应用的依赖中自带了log4j.properties，则有可能导致将jstorm默认的本地测试的log4j配置覆盖掉，从而导致调试时控制台没有任何输出。]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>安装</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提高Elasticsearch性能的配置建议]]></title>
    <url>%2F2017%2F03%2F18%2Felasticsearch%2F</url>
    <content type="text"><![CDATA[之前公司项目中有使用Elasticsearch存储日志，当时使用的功能简单，并没有深入了解Elasticsearch，但是对于该支持文本搜索的存储架构还是很感兴趣，最近因为想在一个新项目中采用ELK（Elasticsearch+Logstash+Kibana）技术栈来存储系统日志，学习有关Elasticsearch的书籍（深入理解Elasticsearch，第二版），现在就书本的第八章——提高性能，总结一些有关使用Elasticsearch的Tips，该书采用的elasticsearch为1.4.X版本。 热点线程检测热点线程API能向你提供系统变慢变卡顿的必需信息，它给出了什么可能是热点的信息，并使你可以看到系统的哪部分需要更深入的分析，例如查询的执行或者Lucene段的合并。热点线程API返回从CPU的角度来看，elasticsearch哪部分的代码可能是热点的信息，或者由于某些原因elasticsearch卡在了哪里。 使用方法通过使用如下的命令你可以查看所有节点或者某些、某个节点的情况。 12/_nodes/hot_threads/_nodes/&#123;node or nodes&#125;/hot_threads 例如为了查看所有节点上的热点线程，你可以执行如下的命令：1curl &apos;localhost:9200/_nodes/hot_threads&apos; 此API支持的参数包括 threads 需要分析的线程数，默认3 interval 前后两次检查的时间间隔 type 需要检查的线程状态的类型，默认是CPU，可以是阻塞、等待等线程状态 snapshots 需要生产堆栈跟踪快照的数量 例如，想要以1s为周期查看所有节点上处于等待状态的热点线程，可以执行命令：1curl &apos;localhost:9200/_nodes/hot_threads?type=wait&amp;interval=1s&apos; 执行原理热点线程检测执行流程如下： elasticsearch选取所有运行的线程，收集线程花费CPU的各种信息。 等待interval参数指定的时间后，再次收集步骤1中同样的信息。 对线程基于其消耗的时间进行排序，取前N（参数threads决定）线程分析 每隔几毫秒，对3中选择的线程获取一些堆栈的快照，（数量由snapshots参数决定） 组合堆栈信息，返回响应 返回的响应包括：线程所属节点、消耗CPU时间的百分比、使用CPU的方式、线程名，最后跟着一个堆栈跟踪信息，通过以上信息可以定位节点的性能问题。 高负载场景的分类高负载场景可以分为三种情况： 专注于高索引负载 专注于高查询负载 高查询索引负载并行 后面按照三个场景进行说明 查询、索引负载均衡场景因为是查询、索引负载均衡的场景，所以一下建议不只是与索引性能、查询性能有关，而是与它们都有关。 正确的存储选择正确的存储实现，在运行1.3版本以后时尤其重要。 如果使用64位系统，考虑使用 mmapfs（内存映射） 基于UNIX系统考虑选择 Niofs windows系统应该选择 simplefs 非持久化的存储考虑 内存存储 elasticsearch 1.3版本以后，默认使用的存储类型是一个 混合 的存储类型default，使用内存映射文件读取term字典，doc values，其他文件采用nio存储。 索引刷新频率索引刷新的频率是指文档需要多长时间才能出现在搜索结果中。规则非常简单：刷新频率越短，查询越慢，且索引文档的吞吐量越低。默认的刷新频率是1s，这意味着索引查询器每1s都会重新打开一次。如果可以接受一个较慢的刷新频率，可以设置成5s、10s、30s等。 线程池调优但你看到节点正在填充队列并且仍然有计算能力剩余，且这些计算能力可以被指定用于处理等待处理操作。线程池调优包括线程数以及等待队列长度两个方面。 调整合并过程Lucene段合并取决与你追加多少数据、多久追加一次等因素，对于Lucene分段和合并，需要记住：有多个段的索引执行查询比只有少量段的索引上执行慢。性能测试显示多个段上执行查询比只有一个段的索引要慢大约10%-15%。 如果你希望查询快，就需要更少的段 段合并限流，默认情况下elasticsearch会限制合并的速度在20MB/s，elasticsearch需要限流来避免合并过程中过多的影响搜索。如果使用的是SSD硬盘，那么默认20MB/s是不适合的，通过一下参数设置： indices.store.throttle.max_bytes_per_sec设置端合并限流 高查询频率场景缓存设置第一个有助于查询性能的缓存是 过滤器缓存 ，可以使用下面的属性，来控制给定节点上能够被过滤器缓存使用的全部内存数量，默认是10%。1indices.cache.filter.size 第二个缓存是 分片查询缓存 ，她的目的是缓存聚合、提示词结果、命中数等，当你的查询使用了聚合、提示词等，最好启用这个缓存。该缓存的大小可以使用如下参数设置：1indices.cache.query.size 查询的思考 总是考虑到优化查询结构、过滤器使用等 过滤器不影响文档的打分，在计算得分时不被考虑进去 使用路由如果数据可以使用路由，你应该考虑使用它，可以避免在请求特定数据查询时查询所有的分片。 控制size和shard_size在处理聚合查询时，合理的设置size、shard_size，size定义了聚合结果返回多少组数据，聚合只会返回前size个结果给客户端；size、shard_size具有相同的意思，只是shard_size其作用是在分片的层次上。 高索引吞吐场景批量索引合理的使用批量索引可以显著提高索引的速度，但不要向elasticsearch发送过多的超出其能力的批量索引请求。 doc value 与索引速度的权衡doc value可以帮助具有 排序、聚合、分组 的操作，但是记录doc value需要在索引时做一些额外的操作，这样会 降低索引速度 和 索引吞吐量 ，所以需要结合具体应用场景，权衡 doc value与索引速度。 控制文档的字段尽量的保持你存储的字段尽可能的少，你在打多少情况下需要保存的字段是_source，在一些场景下需要判断是否需要存储 _all、_source 等字段。在禁用_all字段时，设置一个新的默认搜索字段是一个很好的实践，使用如下命令设置：1index.query.default_field：set_your_name 调整事务日志elasticsearch使用事务日志来获取最新的更新，确保数据的持久化以及优化Lucene索引的写入，默认的事务日志最多保留5000个操作，或者最多占用200MB的空间。两者的参数设置如下：12index.translog.flush_threshold_opsindex.translog.flush_threshold_size 如果需要获取更大的索引吞吐量，愿意付出数据在更长的时间内不能被搜索到，可以调高以上两个默认值。并且在故障发生时，拥有大量事务日志的节点需要更长时间去恢复。 最后以上是有关elasticsearch使用中的小Tips，后期有时间会继续写一些有关elk技术栈的文章。 转载请标明出处]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Elasticsearch</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客搭建与配置：Hexo-github-域名绑定]]></title>
    <url>%2F2016%2F10%2F11%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%9AHexo-github-%E5%9F%9F%E5%90%8D%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[最近想搭建个人的博客网站，查询一些信息以后决定采用Hexo+Github Pages的方式。该方法站在巨人的肩膀上，很是方便快捷，找了个很喜欢的主题，做了点配置就可以，最后在阿里云上买了个域名，成功搞定就差写博客了。这里就说一下建站的整个过程。个人博客地址http://he-zhao.cn 前期准备 Github账号注册 Node.js安装 git安装 Github Pages注册了Github账号以后，每个账号可以建一个Github Pages Create a new repository后，严格使用你的github用户名+.github.io命名新的repository，例如我的用户名为mrgiser，新建的取名为 mrgiser.github.io，其他设置不用关心，这样GIthub Pages 所需要的版本库也创建好了。 安装Hexo安装好Git跟Node.js后，在cmd中执行12$ npm install -g hexo-cli //安装hexo客户端$ npm install hexo-deployer-git --save //安装用于部署到Git的插件 以上完成之后，执行下面的命令，Hexo将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 至此，hexo安装完成。 修改主题其实安装hexo的过程很简单，主要时间花在了找主题以及主题配置上了。我选择了一款在NexT上修改的主题iissnan。 进入Hexo文件夹。然后使用下面的命令clone下iissnan主题，主题的文件代码将被下载至themes/iissnan文件夹中。1$ git clone https://github.com/mrgiser/mrgiser.github.io.git themes/iissnan 打开博客主文件夹下的_config.yml，修改其中的theme 属性。theme: 后面要加空格。1theme: iissnan 本地部署部署在本地方便查看调试效果，命令如下：12$ hexo g #在public文件夹下生成静态页面$ hexo s #启动本地服务，进行文章预览调试,浏览器输入http://localhost:4000查看效果 发布到Github Pages先对Git进行配置：12$ git config --global user.name &quot;your name&quot;$ git config --global user.email &quot;email@email.com&quot; 博客主文件夹下的_config.yml,也就是 站点配置文件 ，配置其中的deploy参数，详细请查看官方文档中部署部分。我的设置如下所示：1234deploy: type: git repository: git@github.com:mrgiser/mrgiser.github.io.git branch: master 配置完成保存后，执行以下命令将代码同步到github pages上：12$ hexo g #需要先生成静态文件$ hexo d #将代码部署到github 输入https://XXXX.github.io访问个人github pages，其中XXXX为你github的用户名。 Hexo配置请记住博客主文件夹下的blog_config.yml为站点配置文件，主题配置文件为blog\themes\iissnan_config.yml。 作者、标题、描述、语言等站点配置修改 站点配置文件 中的如下配置：1234567# Sitetitle: Pegasussubtitle: description: 记录生活，写点东西author: Pegasus.Helanguage: zh-Hanstimezone: 导航栏与侧边栏在导航栏中加入归档、分类、标签、关于等，在主题配置文件中修改如下部分123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th about: /about/ || user 社交信息添加在主题配置文件中修改如下部分123456social: GitHub: https://github.com/XXXXXX|| github E-Mail: mailto:XXXXXXXX || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook 头像在主题配置文件中修改如下部分,添加头像照片1234# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: /images/IMG_3428.JPG 其他主题配置其他主题配置可参考next使用文档，Git上的有关主题的问答 域名配置这里讲述在阿里云上购买的域名如何配置，登陆阿里云-控制台-域名服务-域名，选择需要配置的域名，点击解析。删除默认所有主机记录为@的记录，添加解析参考如下： 在blog\source\文件夹下新建文件CNAME（在此新建文件，可以保证hexo d的时候不会删除掉），文本打开编辑，添加个人购买的域名，例如he-zhao.cn重新部署12$ hexo g #需要先生成静态文件$ hexo d #将代码部署到github 至此域名绑定就完成了，访问自己的域名时，会显示github pages的页面。 写在最后个人博客网站建好了，更重要的是好好记录。最后个人博客地址希望支持，后期会增加一些技术博客，希望支持。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2013%2F07%2F13%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hello World</tag>
        <tag>安装</tag>
      </tags>
  </entry>
</search>
