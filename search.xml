<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Flux模式开发提交JStorm任务]]></title>
    <url>%2F2017%2F12%2F02%2Fjstormflux%2F</url>
    <content type="text"><![CDATA[传统法式采用提交jar包的方式运行topology，一旦我们需要改变拓扑里头的相应配置，我们就必须重新编译和打包，而Flux可以帮助我们创建和部署jstorm拓扑的编程框架及组件。它可以将你代码中有关topology结构以及提交部分用一句话加上配置文件完成。 传统方式在jar内完成topology的构建以及数据流配置，代码可能如下：1234567891011121314151617TopologyBuilder builder = new TopologyBuilder();builder.setSpout(&quot;send&quot;,new genRandomSentenceSpout());builder.setBolt(&quot;split&quot;,new splitSentenceBolt()).shuffleGrouping(&quot;send&quot;); builder.setBolt(&quot;count&quot;,new wordCountBolt()).fieldsGrouping(&quot;split&quot;,new Fields(&quot;word&quot;));Config conf=new Config();conf.setNumWorkers(1);conf.setNumAckers(1);boolean runLocal = shouldRunLocal();if(runLocal)&#123; LocalCluster cluster = new LocalCluster(); cluster.submitTopology(name, conf, builder.createTopology()); //本地提交&#125; else &#123; StormSubmitter.submitTopology(name, conf, builder.createTopology()); //集群提交 &#125;&#125; 使用Flux，上面代码可用如下Flux命令代替：12jstorm jar mytopology.jar com.alibaba.jstorm.flux.Flux --local config.yaml //本地提交jstorm jar mytopology.jar com.alibaba.jstorm.flux.Flux --remote config.yaml //远程提交 Flux方式开发maven依赖与打包配置由于需要maven依赖flux-core，而flux-core在网上没有链接可以下载，所以需要手动生产安装。通过集群版本下载对应JStorm源码，maven中编译安装JStorm-Flux，会在你本地maven仓库中安装jstorm-core.jar。 然后在开发topology项目中添加maven依赖：1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;flux-core&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 如下代码以maven-shade打包为例，在pom.xml中添加打包方式，其中mainClass设置为com.alibaba.jstorm.flux.Flux123456789101112131415161718192021222324252627&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;true&lt;/createDependencyReducedPom&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot; /&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.alibaba.jstorm.flux.Flux&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 配置文件开发完spout、bolt后不需要在main函数中显示配置topology的结构，采用配置文件的方式来构建topology结构。例如如下的代码跟配置文件在效果上是一样的。1234567891011//代码方式构建topologyTopologyBuilder builder = new TopologyBuilder();builder.setSpout(&quot;send&quot;,new genRandomSentenceSpout());builder.setBolt(&quot;split&quot;,new splitSentenceBolt()).shuffleGrouping(&quot;send&quot;); builder.setBolt(&quot;count&quot;,new wordCountBolt()).fieldsGrouping(&quot;split&quot;,new Fields(&quot;word&quot;));Config conf=new Config();conf.setNumWorkers(1);conf.setNumAckers(1);StormSubmitter. submitTopology(topo_name , conf, builder.createTopology() ); 123456789101112131415161718192021222324252627282930313233343536# Flux配置文件方式---# 定义topology名name: &quot;flux&quot;# topology有关配置，worker、acker数量配置config: topology.workers: 1 topology.ackers: 1# spouts配置spouts: - id: &quot;word-spout&quot; className: &quot;spout.genRandomSentenceSpout&quot;parallelism: 1# Bolt配置bolts: - id: &quot;word-counter&quot; className: &quot;bolt.wordCountBolt&quot; parallelism: 1 - id: &quot;split-bolt&quot; className: &quot;bolt.splitSentenceBolt&quot; parallelism: 1# 数据流配置streams: - name: &quot;word-spout --&gt; split-bolt&quot; # name isn&apos;t used (placeholder for logging, UI, etc.) from: &quot;word-spout&quot; to: &quot;split-bolt&quot; grouping: type: SHUFFLE - name: &quot;split-bolt --&gt; word-counter&quot; from: &quot;split-bolt&quot; to: &quot;word-counter&quot; grouping: type: SHUFFLE args: [&quot;word&quot;] 发布提交一旦你用flux完成了topology打包，你就可以利用配置文件来跑各种拓扑啦。比如你的jar名称为myTopology-0.1.0-SNAPSHOT.jar， 你可以利用以下命令跑本地模式1jstorm jar myTopology-0.1.0-SNAPSHOT.jar com.alibaba.jstorm.flux.Flux --local my_config.yaml 当然你也可以跑分布式模式1jstorm jar myTopology-0.1.0-SNAPSHOT.jar com.alibaba.jstorm.flux.Flux --remote my_config.yaml]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JStorm运行依赖storm-core的任务：依赖冲突与解决]]></title>
    <url>%2F2017%2F11%2F29%2FJStorm%E8%BF%90%E8%A1%8C%E4%BE%9D%E8%B5%96storm-core%E7%9A%84%E4%BB%BB%E5%8A%A1%EF%BC%9A%E4%BE%9D%E8%B5%96%E5%86%B2%E7%AA%81%E4%B8%8E%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[JStorm虽然用Java语言重新实现了storm，但是对于storm的external部分并未实现。现在在JStorm基础上构建topology时，需要使用storm的external部分中的storm-sql-core以及storm-sql-runtime，这样在构建topology的项目中需要同时依赖storm-core、jstorm-core，出现了冲突。 本地调试问题Found multiple defaults.yaml resources根据前面描述的情况，maven的pom.xml文件将包含如下的依赖jstorm-core、storm-core、storm-sql-core、storm-sql-runtime。123456789101112131415161718192021222324&lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;jstorm-core&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;!--本地调试时注释一下scope --&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-sql-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.storm&lt;/groupId&gt; &lt;artifactId&gt;storm-sql-runtime&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt; 此时按照JStorm本地调试的模式在ide中运行，12345LocalCluster cluster = new LocalCluster();cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology());Utils.sleep(20000);cluster.killTopology(TOPOLOGY_NAME);cluster.shutdown(); 出现如下报错：123456789101112131415161718192021Exception in thread &quot;main&quot; java.lang.ExceptionInInitializerErrorat backtype.storm.topology.BaseConfigurationDeclarer.(BaseConfigurationDeclarer.java:29)at backtype.storm.topology.TopologyBuilder$ConfigGetter.(TopologyBuilder.java:433)at backtype.storm.topology.TopologyBuilder$SpoutGetter.(TopologyBuilder.java:450)at backtype.storm.topology.TopologyBuilder.setSpout(TopologyBuilder.java:289)at com.ctg.itrdc.ruleengine.JsonTopology.main(JsonTopology.java:34)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Caused by: java.lang.RuntimeException: Invalid configuration defaults.yaml:Found multiple defaults.yaml resources. You&apos;re probably bundling the Storm jars with your topology jar. [jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/com/alibaba/jstorm/jstorm-core/2.2.1/jstorm-core-2.2.1.jar!/defaults.yaml, jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/org/apache/storm/storm-core/1.1.1/storm-core-1.1.1.jar!/defaults.yaml]at com.alibaba.jstorm.utils.LoadConf.findAndReadYaml(LoadConf.java:77)at backtype.storm.utils.Utils.readDefaultConfig(Utils.java:355)at backtype.storm.utils.Utils.readStormConfig(Utils.java:453)at backtype.storm.utils.Utils.(Utils.java:112)... 10 moreCaused by: java.io.IOException: Found multiple defaults.yaml resources. You&apos;re probably bundling the Storm jars with your topology jar. [jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/com/alibaba/jstorm/jstorm-core/2.2.1/jstorm-core-2.2.1.jar!/defaults.yaml, jar:file:/E:/Program%20Files%20(x86)/apache-maven-3.3.1-bin/repos/repository/org/apache/storm/storm-core/1.1.1/storm-core-1.1.1.jar!/defaults.yaml]at com.alibaba.jstorm.utils.LoadConf.getConfigFileInputStream(LoadConf.java:101)at com.alibaba.jstorm.utils.LoadConf.findAndReadYaml(LoadConf.java:55)... 13 more 可以看出是因为同时依赖了jstorm-core、storm-core导致存在多个配置文件加载出错。 解决方法解决的方法比较暴力，pom.xml文件不需要做修改，保持jstorm-core、storm-core等被注释了，找到冲突的本地maven仓库中的/repository/org/apache/storm/storm-core/1.1.1/storm-core-1.1.1.jar，将jar包下的defaults.yaml删除。采用本地模式提交topology，注意有关提交topology的类，依赖自JStorm中的import backtype.storm.xxx、不要继承自import org.apache.storm.xxx。以上，主要是删除storm中有冲突的配置文件defaults.yaml。 集群模式问题问题1:Invalid signature file digest for Manifest main attributes修改pom.xml，将jstorm-core、storm-core设置为provided，修改本地提交代码为集群提交：StormSubmitter. submitTopology(topo_name , config, builder.createTopology() );打包后去集群上执行，提交失败，报错：Exception in thread “main” java.lang.SecurityException: Invalid signature file digest for Manifest main attributes12345678910111213141516171819202122232425262728293031323334353637$ ./jstorm jar ~/topology/ruleengine-0.0.1-SNAPSHOT.jar com.ctg.itrdc.ruleengine.JsonTopology ruleengine2/usr/java/jdk1.8.0_111/bin/javaException in thread &quot;main&quot; java.lang.ExceptionInInitializerError at backtype.storm.command.config_value.main(config_value.java:40)Caused by: java.lang.SecurityException: Invalid signature file digest for Manifest main attributes at sun.security.util.SignatureFileVerifier.processImpl(SignatureFileVerifier.java:314) at sun.security.util.SignatureFileVerifier.process(SignatureFileVerifier.java:268) at java.util.jar.JarVerifier.processEntry(JarVerifier.java:316) at java.util.jar.JarVerifier.update(JarVerifier.java:228) at java.util.jar.JarFile.initializeVerifier(JarFile.java:383) at java.util.jar.JarFile.getInputStream(JarFile.java:450) at sun.misc.URLClassPath$JarLoader$2.getInputStream(URLClassPath.java:940) at sun.misc.Resource.cachedInputStream(Resource.java:77) at sun.misc.Resource.getByteBuffer(Resource.java:160) at java.net.URLClassLoader.defineClass(URLClassLoader.java:454) at java.net.URLClassLoader.access$100(URLClassLoader.java:73) at java.net.URLClassLoader$1.run(URLClassLoader.java:368) at java.net.URLClassLoader$1.run(URLClassLoader.java:362) at java.security.AccessController.doPrivileged(Native Method) at java.net.URLClassLoader.findClass(URLClassLoader.java:361) at java.lang.ClassLoader.loadClass(ClassLoader.java:424) at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) at java.lang.ClassLoader.loadClass(ClassLoader.java:357) at backtype.storm.utils.Utils.&lt;clinit&gt;(Utils.java:103) ... 1 moreFailed to get config java.library.pathNoneruleengine2cannot concatenate &apos;str&apos; and &apos;NoneType&apos; objectsSyntax: [jstorm jar topology-jar-path class ...] Runs the main method of class with the specified arguments. The jstorm jars and configs in $JSTORM_CONF_DIR/storm.yaml are put on the classpath. The process is configured so that StormSubmitter (https://github.com/alibaba/jstorm/wiki/JStorm-Chinese-Documentation) will upload the jar at topology-jar-path when the topology is submitted. 解决方法1谷歌后发现，Exception in thread “main” java.lang.SecurityException: Invalid signature file digest for Manifest main attributes错误是maven打包时设置的问题，修改打包配置如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;1.7.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;transformers&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.AppendingTransformer&quot;&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer&quot;&gt; &lt;mainClass&gt;com.ctg.itrdc.ruleengine.JsonTopology&lt;/mainClass&gt; &lt;/transformer&gt; &lt;/transformers&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 主要是添加如下部分。12345678910&lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt;&lt;/filters&gt; 问题 2:storm-core类加载失败按照在Git上的看到的回复，集群运行时，设置依赖的时候jstorm和storm的依赖应该都设置成provided。解决了问题1后，成功提交topology，能够成功运行，在web-UI中查看日志也没有出错，但是topology运行的结果不对。 猜测是storm-sql-core以及storm-sql-runtime依赖了storm-core，但是因为jstorm-core、storm-core设置为provided，但是JStorm集群中只有jstorm-core是provided，而storm-core仍然是没有提供。 坑的是类加载失败错误是直接system.out.print，而不是会打印log，所以在Web-UI中是看不到具体错误的。继续按照猜测走下去，在pom.xml中将storm-core的provided注释掉:1&lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; 打包提交，成功加载了storm-core的类，且topology正常运行没有报错,问题解决。]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何本地调试-JStorm程序]]></title>
    <url>%2F2017%2F11%2F15%2F%E5%A6%82%E4%BD%95%E6%9C%AC%E5%9C%B0%E8%B0%83%E8%AF%95-JStorm-%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[JStorm 提供了两种运行模式：本地模式和分布式模式。本地模式针对开发调试storm topologies非常有用。 如果你还在用日常的web ui提交拓扑这种远古的方式进行调试测试，那就赶快阅读本文吧。本文将介绍在本机不安装JStorm环境的情况下，开发、调试JStorm程序。 单机模式主要是在代码中加入：import backtype.storm.LocalCluster; LocalCluster cluster = new LocalCluster(); //建议加上这行，使得每个bolt/spout的并发度都为1 conf.put(Config.TOPOLOGY_MAX_TASK_PARALLELISM, 1); //提交拓扑 cluster.submitTopology("SequenceTest", conf, builder.createTopology()); //等待1分钟， 1分钟后会停止拓扑和集群， 视调试情况可增大该数值 Thread.sleep(60000); //结束拓扑 cluster.killTopology("SequenceTest"); cluster.shutdown(); 用LocalCluster来模拟集群环境，你可以在LocalCluster对象上调用submitTopology方法来提交拓扑，submitTopology(String topologyName, Map conf, StormTopology topology)接受一个拓扑名称，一个拓扑的配置，以及一个拓扑的对象。就像StormSubmitter一样。你还可以调用killTopology来结束一个拓扑。对应的还有active,deactive,rebalance等方法。由于JStorm是个不会停止的程序，所以我们最后需要显示地停掉集群。 修改pom.xml以jstorm 2.1.1版本为例。 &lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;jstorm-core&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;!-- keep jstorm out of the jar-with-dependencies --&gt; &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt; &lt;/dependency&gt; 注意要注释掉jstorm依赖中的&lt;scope&gt;provided&lt;/scope&gt;，而提交的时候必须记得将这行改回来！ 否则会报多个defaults.yaml的错误。 注：如果依赖的是 0.9.x 版本的jstorm，会有三个依赖包，将这三个依赖的provided都注释掉。 Re-import 项目， 然后运行main class就可以了。为了更好的代码组织，建议将本地运行和集群运行写成两个方法，根据参数/配置来调用不同的运行方式。更多可以参照SequenceTopology的例子 注意点本地调试主要是用于测试应用逻辑的，因此有一些限制，如classloader是不起作用的。此外，还需要注意一下你的应用中log4j的依赖，如果应用的依赖中自带了log4j.properties，则有可能导致将jstorm默认的本地测试的log4j配置覆盖掉，从而导致调试时控制台没有任何输出。]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>大数据</tag>
        <tag>java</tag>
        <tag>安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JStorm：单词计数-开发示例]]></title>
    <url>%2F2017%2F09%2F12%2FWordCountTopology%2F</url>
    <content type="text"><![CDATA[JStorm：概念与编程模型JStorm：任务调度示例功能说明：统计单词出现的次数，spout将持续输入的一句句话作为输入流，bolt将一句话分割成单词，最后统计每个单词出现的次数。 示例介绍如下图所示，单词计数topology由一个spout和下游三个bolt组成。SentenceSpout：向后端发射一个单值tuple组成的数据流，键名“sentence”，tuple如下：{“sentence”：“my name is zhangsan”}SplitSentenceBolt：订阅SentenceSpout发射的数据流，将“sentence”中的语句分割为一个个单词，向后端发射“word”组成的tuple如下：{“word”：“my”}{“word”：“name”}{“word”：“is”}{“word”：“zhangsan”}WordCountBolt：订阅SplitSentenceBolt发射的数据流，保存每个特定单词出现的次数，每当bolt收到一个tuple，将对应单词的计数加一，并想后发射该单词当前的计数。{“word”:“my”,“count”:“5”}ReportBolt：订阅WordCountBolt的输出流，维护一份所有单词对应的计数表，结束时将所有值打印。 代码实现添加Pom.xml依赖123456&lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;jstorm-core&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt; &lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;&lt;/dependency&gt; SentenceSpout：继承BaseRichSpout类，在nextTuple方法中生成并向后发射数据流，declareOutputFields方法定义了向后发射数据流tuple的字段名为：sentence。SplitSentenceBolt：继承BaseRichBolt类，在execute方法中将接收到的tuple分割为单词，并向后传输tuple，declareOutputFields定义了tuple字段为word。WordCountBolt：继承BaseRichBolt，在execute方法中统计单词出现的次数，本地使用HashMap保存所有单词出现的次数。接收到tuple后更新该单词出现的次数并向后传输tuple，declareOutputFields定义了tuple为”word”, “count”。ReportBolt：继承BaseRichBolt类，在execute方法中汇总所有单词出现的次数。本地使用HashMap保存所有单词出现的次数。当任务结束时，Cleanup方法打印统计结果。WordCountTopology：创建topology，定义了Spout以及Bolt之间数据流传输的规则，以及并发数（前后并发为2、2、4、1）。进程（worker）、线程（Executor）与Task之间的关系如下图：核心代码参考如下，注意其中的shuffleGrouping设定向后传输数据流为随机，fieldsGrouping按照字段值向后传输数据流，能保证同一个单词由同一个WordCountBolt统计，而globalGrouping保证汇总的bolt是单例。 WordCountTopology.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//WordCountTopology代码import storm.blueprints.word.v1.*;import backtype.storm.Config;import backtype.storm.LocalCluster;import backtype.storm.topology.TopologyBuilder;import backtype.storm.tuple.Fields;import static storm.blueprints.utils.Utils.*;public class WordCountTopology &#123; private static final String SENTENCE_SPOUT_ID = &quot;sentence-spout&quot;; private static final String SPLIT_BOLT_ID = &quot;split-bolt&quot;; private static final String COUNT_BOLT_ID = &quot;count-bolt&quot;; private static final String REPORT_BOLT_ID = &quot;report-bolt&quot;; private static final String TOPOLOGY_NAME = &quot;word-count-topology&quot;; public static void main(String[] args) throws Exception &#123; SentenceSpout spout = new SentenceSpout(); SplitSentenceBolt splitBolt = new SplitSentenceBolt(); WordCountBolt countBolt = new WordCountBolt(); ReportBolt reportBolt = new ReportBolt(); TopologyBuilder builder = new TopologyBuilder(); builder.setSpout(SENTENCE_SPOUT_ID, spout, 2); // SentenceSpout --&gt; SplitSentenceBolt builder.setBolt(SPLIT_BOLT_ID, splitBolt, 2) .setNumTasks(4) .shuffleGrouping(SENTENCE_SPOUT_ID); // SplitSentenceBolt --&gt; WordCountBolt builder.setBolt(COUNT_BOLT_ID, countBolt, 4) .fieldsGrouping(SPLIT_BOLT_ID, new Fields(&quot;word&quot;)); // WordCountBolt --&gt; ReportBolt builder.setBolt(REPORT_BOLT_ID, reportBolt) .globalGrouping(COUNT_BOLT_ID); Config config = new Config(); config.setNumWorkers(2); LocalCluster cluster = new LocalCluster(); cluster.submitTopology(TOPOLOGY_NAME, config, builder.createTopology()); waitForSeconds(10); cluster.killTopology(TOPOLOGY_NAME); cluster.shutdown(); &#125;&#125; SentenceSpout.java12345678910111213141516171819202122232425262728293031323334353637383940import backtype.storm.spout.SpoutOutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.topology.base.BaseRichSpout;import backtype.storm.tuple.Fields;import backtype.storm.tuple.Values;import storm.blueprints.utils.Utils;import java.util.Map;public class SentenceSpout extends BaseRichSpout &#123; private SpoutOutputCollector collector; private String[] sentences = &#123; &quot;my dog has fleas&quot;, &quot;i like cold beverages&quot;, &quot;the dog ate my homework&quot;, &quot;don&apos;t have a cow man&quot;, &quot;i don&apos;t think i like fleas&quot; &#125;; private int index = 0; public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(&quot;sentence&quot;)); &#125; public void open(Map config, TopologyContext context, SpoutOutputCollector collector) &#123; this.collector = collector; &#125; public void nextTuple() &#123; this.collector.emit(new Values(sentences[index])); index++; if (index &gt;= sentences.length) &#123; index = 0; &#125; Utils.waitForMillis(1000); &#125;&#125; SplitSentenceBolt.java12345678910111213141516171819202122232425262728import backtype.storm.task.OutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.topology.base.BaseRichBolt;import backtype.storm.tuple.Fields;import backtype.storm.tuple.Tuple;import backtype.storm.tuple.Values;import java.util.Map;public class SplitSentenceBolt extends BaseRichBolt&#123; private OutputCollector collector; public void prepare(Map config, TopologyContext context, OutputCollector collector) &#123; this.collector = collector; &#125; public void execute(Tuple tuple) &#123; String sentence = tuple.getStringByField(&quot;sentence&quot;); String[] words = sentence.split(&quot; &quot;); for(String word : words)&#123; this.collector.emit(new Values(word)); &#125; &#125; public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(&quot;word&quot;)); &#125;&#125; WordCountBolt.java1234567891011121314151617181920212223242526272829303132333435import backtype.storm.task.OutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.topology.base.BaseRichBolt;import backtype.storm.tuple.Fields;import backtype.storm.tuple.Tuple;import backtype.storm.tuple.Values;import java.util.HashMap;import java.util.Map;public class WordCountBolt extends BaseRichBolt&#123; private OutputCollector collector; private HashMap&lt;String, Long&gt; counts = null; public void prepare(Map config, TopologyContext context, OutputCollector collector) &#123; this.collector = collector; this.counts = new HashMap&lt;String, Long&gt;(); &#125; public void execute(Tuple tuple) &#123; String word = tuple.getStringByField(&quot;word&quot;); Long count = this.counts.get(word); if(count == null)&#123; count = 0L; &#125; count++; this.counts.put(word, count); this.collector.emit(new Values(word, count)); &#125; public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; declarer.declare(new Fields(&quot;word&quot;, &quot;count&quot;)); &#125;&#125; ReportBolt.java1234567891011121314151617181920212223242526272829303132333435363738394041import backtype.storm.task.OutputCollector;import backtype.storm.task.TopologyContext;import backtype.storm.topology.OutputFieldsDeclarer;import backtype.storm.topology.base.BaseRichBolt;import backtype.storm.tuple.Tuple;import java.util.ArrayList;import java.util.Collections;import java.util.HashMap;import java.util.List;import java.util.Map;public class ReportBolt extends BaseRichBolt &#123; private HashMap&lt;String, Long&gt; counts = null; public void prepare(Map config, TopologyContext context, OutputCollector collector) &#123; this.counts = new HashMap&lt;String, Long&gt;(); &#125; public void execute(Tuple tuple) &#123; String word = tuple.getStringByField(&quot;word&quot;); Long count = tuple.getLongByField(&quot;count&quot;); this.counts.put(word, count); &#125; public void declareOutputFields(OutputFieldsDeclarer declarer) &#123; // this bolt does not emit anything &#125; @Override public void cleanup() &#123; System.out.println(&quot;--- FINAL COUNTS ---&quot;); List&lt;String&gt; keys = new ArrayList&lt;String&gt;(); keys.addAll(this.counts.keySet()); Collections.sort(keys); for (String key : keys) &#123; System.out.println(key + &quot; : &quot; + this.counts.get(key)); &#125; System.out.println(&quot;--------------&quot;); &#125;&#125; Utils.java12345678910111213141516public class Utils &#123; public static void waitForSeconds(int seconds) &#123; try &#123; Thread.sleep(seconds * 1000); &#125; catch (InterruptedException e) &#123; &#125; &#125; public static void waitForMillis(long milliseconds) &#123; try &#123; Thread.sleep(milliseconds); &#125; catch (InterruptedException e) &#123; &#125; &#125;&#125; 转载请标明出处]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>大数据</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JStorm：任务调度]]></title>
    <url>%2F2017%2F09%2F10%2FJstormmanage%2F</url>
    <content type="text"><![CDATA[前一篇文章 JStorm：概念与编程模型 介绍了JStorm的基本概念以及编程模型方面的知识，本篇主要介绍自己对JStorm的任务调度方面的认识，主要从三个方面介绍： 调度角色 调度方法 自定义调度 调度角色上图是JStorm中一个topology对应的任务执行结构，其中worker是进程，executor对应于线程，task对应着spout或者bolt组件。 WorkerWorker是task的容器， 同一个worker只会执行同一个topology相关的task。 一个topology可能会在一个或者多个worker（工作进程）里面执行，每个worker执行整个topology的一部分。比如，对于并行度是300的topology来说，如果我们使用50个工作进程来执行，那么每个工作进程会处理其中的6个tasks。Storm会尽量均匀的工作分配给所有的worker。 ExecutorExecutor是在worker中的执行线程，在同一类executor中，要么全部是同一个bolt类的task，要么全部是同一个spout类的task，需要注意的是， 一个executor只能同时运行一个task，创建时将多个task设置在一个executor中，在前期Storm中主要考虑的是后期线程扩展（待验证），但是在JStorm中可以在rebalance时改变Task的数量，所以不需要将task数量大于executor。 TaskTask是真正任务的执行者，对应创建topology时建立的一个bolt或者spout组件。每一个spout和bolt会被当作很多task在整个集群里执行。可以调用TopologyBuilder类的setSpout和setBolt来设置并行度（也就是有多少个task）。 调度方法默认调度算法默认调度算法遵循以下的原则： 任务调度算法以worker为维度，尽量将平均分配到各个supervisor上； 以worker为单位，确认worker与task数目大致的对应关系(注意在这之前已经其他拓扑占用利用的worker不再参与本次动作)； 建立task-worker关系的优先级依次为：尽量避免同类task在同一work和supervisor下的情况，尽量保证task在worker和supervisor基准上平均分配，尽量保证有直接信息流传输的task在同一worker下。 调度过程中正在进行的调度动作不会对已发生的调度动作产生影响 调度示例如下是一个topology创建时配置代码，以及运行时的示意图。1234567891011//创建topology配置代码Config conf = new Config();conf.setNumWorkers(2); // use two worker processestopologyBuilder.setSpout(&quot;blue-spout&quot;, new BlueSpout(), 2);topologyBuilder.setBolt(&quot;green-bolt&quot;, new GreenBolt(), 2) .setNumTasks(4) .shuffleGrouping(&quot;blue-spout&quot;);topologyBuilder.setBolt(&quot;yellow-bolt&quot;, new YellowBolt(), 6) .shuffleGrouping(&quot;green-bolt&quot;);StormSubmitter.submitTopology(&quot;mytopology&quot;, conf, topologyBuilder.createTopology()); 参考以上代码，以及任务调度算法，该拓扑中，设为worker为2，蓝色Spout并发设置为2，task默认与并发相同为2；绿色Bolt执行并发为2，但设置其task为4，所以每个executor中有两个Task，黄色Bolt并发为6，task默认与并发相同为6。图中两个worker是一致的，可以认为是JStorm分配任务时做的权衡，尽量分配的均匀，不代表所有情况都是如此。 分发过程上图是storm的示例，JStorm雷同。JStorm任务分发过程： 客户端提交拓扑到nimbus，并开始执行； Nimbus针对该拓扑建立本地的目录，根据topology的配置计算task，分配task，在zookeeper上建立assignments节点存储task和supervisor机器节点中woker的对应关系； 在zookeeper上创建taskbeats节点来监控task的心跳；启动topology。 各Supervisor去zookeeper上获取分配的tasks，启动多个woker进行，每个woker生成task；根据topology信息初始化建立task之间的连接。 自定义调度JStorm支持一下自定义调度设置： 设置每个worker的默认内存大小 1ConfigExtension.setMemSizePerWorker(Map conf, long memSize) 设置每个worker的cgroup,cpu权重 1ConfigExtension.setCpuSlotNumPerWorker(Map conf, int slotNum) 设置是否使用旧的分配方式 1ConfigExtension.setUseOldAssignment(Map conf, boolean useOld) 设置强制某个component的task 运行在不同的节点上 1ConfigExtension.setTaskOnDifferentNode(Map componentConf, boolean isIsolate) 注意，这个配置componentConf是component的配置， 需要执行addConfigurations 加入到spout或bolt的configuration当中 自定义worker分配1234567WorkerAssignment worker = new WorkerAssignment();worker.addComponent(String compenentName, Integer num);//在这个worker上增加一个taskworker.setHostName(String hostName);//强制这个worker在某台机器上worker.setJvm(String jvm);//设置这个worker的jvm参数worker.setMem(long mem); //设置这个worker的内存大小worker.setCpu(int slotNum); //设置cpu的权重大小ConfigExtension.setUserDefineAssignment(Map conf, List&lt;WorkerAssignment&gt; userDefines) 注:每一个worker的参数并不需要被全部设置,worker属性在合法的前提下即使只设置了部分参数也仍会生效 强制topology运行在一些supervisor上在实际应用中， 常常一些机器部署了本地服务（比如本地DB）， 为了提高性能， 让这个topology的所有task强制运行在这些机器上1conf.put(Config.ISOLATION_SCHEDULER_MACHINES, List&lt;String&gt; isolationHosts) conf 是topology的configuration 转载请标明出处]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>大数据</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JStorm：概念与编程模型]]></title>
    <url>%2F2017%2F08%2F25%2FJStorm1%2F</url>
    <content type="text"><![CDATA[1、集群架构JStorm从设计的角度，就是一个典型的调度系统，简单集群的架构如下图所示，其中Nimbus可增加一个备节点，多个Supervisor节点组成任务执行集群。 1.1、NimbusNimbus是作为整个集群的调度器角色，负责分发topology代码、分配任务，监控集群运行状态等，其主要通过ZK与supervisor交互。可以和Supervisor运行在同一物理机上，JStorm中Nimbus可采用主从备份，支持热切。 1.2、SupervisorSupervisor 是集群中任务的执行者，负责运行具体任务以及关闭任务。其从ZK中监听nimbus的指令，然后接收分发代码和任务并执行、监控反馈任务执行情况。 1.3 、ZookeeperZK是整个系统中的协调者，Nimbus的任务调度通过ZK下发至Supervisor来执行。 2、Topology编程模型Topology是一个可以在JStorm中运行的任务的抽象表达，在JStorm的topology中，有两种组件：spout和bolt。下面是一张比较经典的Topology结构图。每一个topology，既可以有多个spout，代表同时从多个数据源接收消息，也可以多个bolt，来执行不同的业务逻辑。一个topology会一直运行直到你手动kill掉，JStorm自动重新分配执行失败的任务。在JStorm中有对于流stream的抽象，流是一个不间断的无界的连续tuple，注意JStorm在建模事件流时，把流中的事件抽象为tuple即元组。我们可以认为spout就是一个一个的水龙头，并且每个水龙头里流出的水是不同的tuple，我们想拿到哪种水tuple就拧开哪个水龙头，然后使用管道将水龙头的水tuple导向到一个水处理器（bolt），水处理器bolt处理后再使用管道导向另一个处理器或者存入容器中。JStorm将上图抽象为Topology即拓扑，拓扑结构是有向无环的，拓扑是Jstorm中最高层次的一个抽象概念，它可以被提交到Jstorm集群执行，一个拓扑就是一个数据流转换图，图中每个节点是一个spout或者bolt，图中的边表示bolt订阅了哪些流，当spout或者bolt发送元组到流时，它就发送元组到每个订阅了该流的bolt。 2.1、spoutJStorm认为每个stream都有一个stream源，也就是原始元组的源头，所以它将这个源头抽象为spout，spout可能是连接消息中间件（如MetaQ， Kafka， TBNotify等），并不断发出消息，也可能是从某个队列中不断读取队列元素并装配为tuple发射。JStorm框架对spout组件定义了一个主要方法：nextTuple，顾名思义，就是获取下一条消息。执行时，可以理解成JStorm框架会不停地调这个接口，以从数据源拉取数据并往bolt发送数据。Tuple是一次消息传递的基本单元，tuple里的每个字段一个名字,并且不同tuple的对应字段的类型必须一样。tuple的字段类型可以是： integer, long, short, byte, string, double, float, boolean和byte array。还可以自定义类型，只要实现对应的序列化器。JStorm中与spout相关的接口主要是ISpout和IRichSpout、IBatchSpout，后两接口实现了对ISpout接口的上层封装。 ISpout接口主要方法：open：在worker中初始化该ISpout时调用，一般用来设置一些属性：比如从spring容器中获取对应的Bean。close：和open相对应（在要关闭的时候调用）。activate：从非活动状态变为活动状态时调用。deactivate：和activate相对应（从活动状态变为非活动状态时调用）。nextTuple：JStorm希望在每次调用该方法的时候，它会通过collector.emit发射一个tuple。ack：jstorm发现msgId对应的tuple被成功地完整消费会调用该方法。fail：和ack相对应（jstorm发现某个tuple在某个环节失败了）。和ack一起保证tuple一定被处理。 2.2、boltJStorm将tuple的中间处理过程抽象为Bolt，bolt可以消费任意数量的输入流，只要将流方向导向该bolt，同时它也可以发送新的流给其他bolt使用，这样一来，只要打开特定的spout（管口）再将spout中流出的tuple导向特定的bolt，然后bolt对导入的流做处理后再导向其他bolt或者目的地。bolt代表处理逻辑，bolt收到消息之后，对消息做处理（即执行用户的业务逻辑），处理完以后，既可以将处理后的消息继续发送到下游的bolt，这样会形成一个处理流水线（不过更复杂的情况应该是个有向图）；也可以直接结束。bolt组件主要方法：execute，这个接口就是用户用来处理业务逻辑的地方。通常一个流水线的最后一个bolt，会做一些数据的存储工作，比如将实时计算出来的数据写入DB、HBase等，以供前台业务进行查询和展现。Bolts可以发射多条消息流， 使用OutputFieldsDeclarer.declareStream定义stream，使用OutputCollector.emit来选择要发射的stream。在保证不丢消息的场景中，在bolts必须要为它处理的每一个tuple调用OutputCollector的ack方法，以通知JStorm这个tuple被处理完成了，从而通知这个tuple的发射者spouts。 一般的流程是： bolts处理一个输入tuple, 发射0个或者多个tuple, 然后调用ack通知JStorm自己已经处理过这个tuple了。JStorm提供了一个IBasicBolt会自动调用ack。JStorm中与Bolt相关的接口主要是IBolt，IRichBolt，IBasicBolt和IBatchBolt，后面接口实现了对IBolt接口的上层封装。 IBolt接口的主要方法：prepare：在worker中初始化该IBolt时调用，一般用来设置一些属性：比如从spring容器中获取对应的Bean。cleanup：和prepare相对应（在显示关闭topology的时候调用）execute：处理jstorm发送过来的tuple。 2.3、TupleJStorm将流中数据抽象为tuple，一个tuple就是一个值列表value list，list中的每个value都有一个name，tuple可以由任意类型组合而成，因为storm是分布式的，所以它需要知道在task间如何序列化和反序列化数据的。storm使用Kryo进行序列化，Kryo是java开发中一个快速灵活序列器。默认情况下，storm可以序列化基础类型，比如字符串，字节，数组，ArrayList, HashMap, HashSet和 Clojure 集合类型，如果需要使用其他类型，需要自定义序列器。拓扑的每个节点都要说明它所发射出的元组的字段的name，其他节点只需要订阅该name就可以接收处理。在spout和Bolt组件中，使用declareOutputFields方法定义发射出的tuple的字段名。 3、小结本文主要讲述了JStorm中集群的架构以及Topology编程模型方面的概念知识，后续会更深入的写一些实践、运维、原理等方面的文章。]]></content>
      <categories>
        <category>JStorm</category>
      </categories>
      <tags>
        <tag>JStorm</tag>
        <tag>Storm</tag>
        <tag>大数据</tag>
        <tag>流计算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提高Elasticsearch性能的配置建议]]></title>
    <url>%2F2017%2F03%2F18%2Felasticsearch%2F</url>
    <content type="text"><![CDATA[之前公司项目中有使用Elasticsearch存储日志，当时使用的功能简单，并没有深入了解Elasticsearch，但是对于该支持文本搜索的存储架构还是很感兴趣，最近因为想在一个新项目中采用ELK（Elasticsearch+Logstash+Kibana）技术栈来存储系统日志，学习有关Elasticsearch的书籍（深入理解Elasticsearch，第二版），现在就书本的第八章——提高性能，总结一些有关使用Elasticsearch的Tips，该书采用的elasticsearch为1.4.X版本。 热点线程检测热点线程API能向你提供系统变慢变卡顿的必需信息，它给出了什么可能是热点的信息，并使你可以看到系统的哪部分需要更深入的分析，例如查询的执行或者Lucene段的合并。热点线程API返回从CPU的角度来看，elasticsearch哪部分的代码可能是热点的信息，或者由于某些原因elasticsearch卡在了哪里。 使用方法通过使用如下的命令你可以查看所有节点或者某些、某个节点的情况。 12/_nodes/hot_threads/_nodes/&#123;node or nodes&#125;/hot_threads 例如为了查看所有节点上的热点线程，你可以执行如下的命令：1curl &apos;localhost:9200/_nodes/hot_threads&apos; 此API支持的参数包括 threads 需要分析的线程数，默认3 interval 前后两次检查的时间间隔 type 需要检查的线程状态的类型，默认是CPU，可以是阻塞、等待等线程状态 snapshots 需要生产堆栈跟踪快照的数量 例如，想要以1s为周期查看所有节点上处于等待状态的热点线程，可以执行命令：1curl &apos;localhost:9200/_nodes/hot_threads?type=wait&amp;interval=1s&apos; 执行原理热点线程检测执行流程如下： elasticsearch选取所有运行的线程，收集线程花费CPU的各种信息。 等待interval参数指定的时间后，再次收集步骤1中同样的信息。 对线程基于其消耗的时间进行排序，取前N（参数threads决定）线程分析 每隔几毫秒，对3中选择的线程获取一些堆栈的快照，（数量由snapshots参数决定） 组合堆栈信息，返回响应 返回的响应包括：线程所属节点、消耗CPU时间的百分比、使用CPU的方式、线程名，最后跟着一个堆栈跟踪信息，通过以上信息可以定位节点的性能问题。 高负载场景的分类高负载场景可以分为三种情况： 专注于高索引负载 专注于高查询负载 高查询索引负载并行 后面按照三个场景进行说明 查询、索引负载均衡场景因为是查询、索引负载均衡的场景，所以一下建议不只是与索引性能、查询性能有关，而是与它们都有关。 正确的存储选择正确的存储实现，在运行1.3版本以后时尤其重要。 如果使用64位系统，考虑使用 mmapfs（内存映射） 基于UNIX系统考虑选择 Niofs windows系统应该选择 simplefs 非持久化的存储考虑 内存存储 elasticsearch 1.3版本以后，默认使用的存储类型是一个 混合 的存储类型default，使用内存映射文件读取term字典，doc values，其他文件采用nio存储。 索引刷新频率索引刷新的频率是指文档需要多长时间才能出现在搜索结果中。规则非常简单：刷新频率越短，查询越慢，且索引文档的吞吐量越低。默认的刷新频率是1s，这意味着索引查询器每1s都会重新打开一次。如果可以接受一个较慢的刷新频率，可以设置成5s、10s、30s等。 线程池调优但你看到节点正在填充队列并且仍然有计算能力剩余，且这些计算能力可以被指定用于处理等待处理操作。线程池调优包括线程数以及等待队列长度两个方面。 调整合并过程Lucene段合并取决与你追加多少数据、多久追加一次等因素，对于Lucene分段和合并，需要记住：有多个段的索引执行查询比只有少量段的索引上执行慢。性能测试显示多个段上执行查询比只有一个段的索引要慢大约10%-15%。 如果你希望查询快，就需要更少的段 段合并限流，默认情况下elasticsearch会限制合并的速度在20MB/s，elasticsearch需要限流来避免合并过程中过多的影响搜索。如果使用的是SSD硬盘，那么默认20MB/s是不适合的，通过一下参数设置： indices.store.throttle.max_bytes_per_sec设置端合并限流 高查询频率场景缓存设置第一个有助于查询性能的缓存是 过滤器缓存 ，可以使用下面的属性，来控制给定节点上能够被过滤器缓存使用的全部内存数量，默认是10%。1indices.cache.filter.size 第二个缓存是 分片查询缓存 ，她的目的是缓存聚合、提示词结果、命中数等，当你的查询使用了聚合、提示词等，最好启用这个缓存。该缓存的大小可以使用如下参数设置：1indices.cache.query.size 查询的思考 总是考虑到优化查询结构、过滤器使用等 过滤器不影响文档的打分，在计算得分时不被考虑进去 使用路由如果数据可以使用路由，你应该考虑使用它，可以避免在请求特定数据查询时查询所有的分片。 控制size和shard_size在处理聚合查询时，合理的设置size、shard_size，size定义了聚合结果返回多少组数据，聚合只会返回前size个结果给客户端；size、shard_size具有相同的意思，只是shard_size其作用是在分片的层次上。 高索引吞吐场景批量索引合理的使用批量索引可以显著提高索引的速度，但不要向elasticsearch发送过多的超出其能力的批量索引请求。 doc value 与索引速度的权衡doc value可以帮助具有 排序、聚合、分组 的操作，但是记录doc value需要在索引时做一些额外的操作，这样会 降低索引速度 和 索引吞吐量 ，所以需要结合具体应用场景，权衡 doc value与索引速度。 控制文档的字段尽量的保持你存储的字段尽可能的少，你在打多少情况下需要保存的字段是_source，在一些场景下需要判断是否需要存储 _all、_source 等字段。在禁用_all字段时，设置一个新的默认搜索字段是一个很好的实践，使用如下命令设置：1index.query.default_field：set_your_name 调整事务日志elasticsearch使用事务日志来获取最新的更新，确保数据的持久化以及优化Lucene索引的写入，默认的事务日志最多保留5000个操作，或者最多占用200MB的空间。两者的参数设置如下：12index.translog.flush_threshold_opsindex.translog.flush_threshold_size 如果需要获取更大的索引吞吐量，愿意付出数据在更长的时间内不能被搜索到，可以调高以上两个默认值。并且在故障发生时，拥有大量事务日志的节点需要更长时间去恢复。 最后以上是有关elasticsearch使用中的小Tips，后期有时间会继续写一些有关elk技术栈的文章。 转载请标明出处]]></content>
      <categories>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Elasticsearch</tag>
        <tag>性能优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[个人博客搭建与配置：Hexo-github-域名绑定]]></title>
    <url>%2F2016%2F10%2F11%2F%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%EF%BC%9AHexo-github-%E5%9F%9F%E5%90%8D%E7%BB%91%E5%AE%9A%2F</url>
    <content type="text"><![CDATA[最近想搭建个人的博客网站，查询一些信息以后决定采用Hexo+Github Pages的方式。该方法站在巨人的肩膀上，很是方便快捷，找了个很喜欢的主题，做了点配置就可以，最后在阿里云上买了个域名，成功搞定就差写博客了。这里就说一下建站的整个过程。个人博客地址http://he-zhao.cn 前期准备 Github账号注册 Node.js安装 git安装 Github Pages注册了Github账号以后，每个账号可以建一个Github Pages Create a new repository后，严格使用你的github用户名+.github.io命名新的repository，例如我的用户名为mrgiser，新建的取名为 mrgiser.github.io，其他设置不用关心，这样GIthub Pages 所需要的版本库也创建好了。 安装Hexo安装好Git跟Node.js后，在cmd中执行12$ npm install -g hexo-cli //安装hexo客户端$ npm install hexo-deployer-git --save //安装用于部署到Git的插件 以上完成之后，执行下面的命令，Hexo将会在指定文件夹中新建所需要的文件。123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 至此，hexo安装完成。 修改主题其实安装hexo的过程很简单，主要时间花在了找主题以及主题配置上了。我选择了一款在NexT上修改的主题iissnan。 进入Hexo文件夹。然后使用下面的命令clone下iissnan主题，主题的文件代码将被下载至themes/iissnan文件夹中。1$ git clone https://github.com/mrgiser/mrgiser.github.io.git themes/iissnan 打开博客主文件夹下的_config.yml，修改其中的theme 属性。theme: 后面要加空格。1theme: iissnan 本地部署部署在本地方便查看调试效果，命令如下：12$ hexo g #在public文件夹下生成静态页面$ hexo s #启动本地服务，进行文章预览调试,浏览器输入http://localhost:4000查看效果 发布到Github Pages先对Git进行配置：12$ git config --global user.name &quot;your name&quot;$ git config --global user.email &quot;email@email.com&quot; 博客主文件夹下的_config.yml,也就是 站点配置文件 ，配置其中的deploy参数，详细请查看官方文档中部署部分。我的设置如下所示：1234deploy: type: git repository: git@github.com:mrgiser/mrgiser.github.io.git branch: master 配置完成保存后，执行以下命令将代码同步到github pages上：12$ hexo g #需要先生成静态文件$ hexo d #将代码部署到github 输入https://XXXX.github.io访问个人github pages，其中XXXX为你github的用户名。 Hexo配置请记住博客主文件夹下的blog_config.yml为站点配置文件，主题配置文件为blog\themes\iissnan_config.yml。 作者、标题、描述、语言等站点配置修改 站点配置文件 中的如下配置：1234567# Sitetitle: Pegasussubtitle: description: 记录生活，写点东西author: Pegasus.Helanguage: zh-Hanstimezone: 导航栏与侧边栏在导航栏中加入归档、分类、标签、关于等，在主题配置文件中修改如下部分123456menu: home: / || home archives: /archives/ || archive tags: /tags/ || tags categories: /categories/ || th about: /about/ || user 社交信息添加在主题配置文件中修改如下部分123456social: GitHub: https://github.com/XXXXXX|| github E-Mail: mailto:XXXXXXXX || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook 头像在主题配置文件中修改如下部分,添加头像照片1234# Sidebar Avatar# in theme directory(source/images): /images/avatar.gif# in site directory(source/uploads): /uploads/avatar.gifavatar: /images/IMG_3428.JPG 其他主题配置其他主题配置可参考next使用文档，Git上的有关主题的问答 域名配置这里讲述在阿里云上购买的域名如何配置，登陆阿里云-控制台-域名服务-域名，选择需要配置的域名，点击解析。删除默认所有主机记录为@的记录，添加解析参考如下： 在blog\source\文件夹下新建文件CNAME（在此新建文件，可以保证hexo d的时候不会删除掉），文本打开编辑，添加个人购买的域名，例如he-zhao.cn重新部署12$ hexo g #需要先生成静态文件$ hexo d #将代码部署到github 至此域名绑定就完成了，访问自己的域名时，会显示github pages的页面。 写在最后个人博客网站建好了，更重要的是好好记录。最后个人博客地址希望支持，后期会增加一些技术博客，希望支持。]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Effective Java读书笔记]]></title>
    <url>%2F2016%2F08%2F13%2FEffectiveJava%2F</url>
    <content type="text"><![CDATA[创建和销毁对象考虑使用静态工厂代替构造函数 静态工厂具有名称，可读性抢 不必在每次调用时都创建新对象，单例模式 可以返回原类型的子类型对象 在创建类似List Map时，代码简洁 缺点：类如果不含有公有或者受保护的构造器，就不能被子类化；其与静态函数没有区别。 遇到多个构造函数参数时，考虑使用构建器 参数多时并可选，构造函数很多，静态工厂也是如此 构建器，set方法返回this，调用可以连接起来。 使用私有构造器或者枚举类型强化单例属性 使用反射机制，可以调用私有构造器 序列化时，提供readResolve方法保证单一 单元素的枚举类型成为实现单例的最佳方法 避免创建不必要的对象 不需要new String，重用不可变的String对象 注意基本类型与装箱类型，优先使用基本类型，装箱类型每次都会新建。 只有在对象非常重量级时，才考虑使用对象池 消除过期的对象引用 如果一个栈先增长，再收缩；从栈中弹出来的对象将不会被当做垃圾回收。Object[] 内存泄露常见来源：缓存、监听器、其他回调 避免使用终结方法 finalizer通常是不可预测的，也是很危险的，一般情况不适用 中介方法的缺点在于不能保证会被及时的执行 java不保证终结方法会被及时的执行，而且根本不保证他们会被执行 异常发生在终结方法中，警告都不会打出 终结方法有一个非常严重的性能损耗 使用终结方法，记得使用super.finalizer 使用try finally代替 所有对象都通用的方法覆盖equals时，遵守通用约定 类具有自己特有的逻辑相等概念时，覆盖equals 需要满足自反性、对称性、传递性、一致性，null必不相等 覆盖equals时必须覆盖hashCode 不要企图让equals过于智能，加上@Override 覆盖Equals时要覆盖hashCode equals所用信息不变，code多次执行结果不变 equals相等，code相同 equals不同，code可能相同，散列的分散性 不要试图从散列码中排除一个关键部分来提高性能 散列码缓存在对象内部 延迟初始化散列码 始终要覆盖toString toString应该包含对象中包含的所有值得关注的信息 谨慎地覆盖clone final与clone冲突 对于一个为了继承而设计的类，如果未能提供行为良好的受保护的clone方法，它的子类就不可能实现cloneable接口 考虑实现Comparable接口 对象小于、等于、大于指定对象时，返回负数、0、正数 自反性、对称性、传递性 类和接口使类和成员的可访问性最小化 信息隐藏与封装是软件设计的原则 有效的解除组成系统的个模块之间的耦合关系 尽可能的使每个类或成员不被外界访问 私有-&gt;包级私有-&gt;收保护-&gt;公有 受保护的成员应该尽少使用，是对外API的一部分，需要维护 长度非零的数组总是可变，类具有公有的静态final数组，或者返回这域的访问方法，几乎总是错误的 在公有类中使用set、get而不是公有域使可变性最小化 不可变对象比较简单 线程安全、不要求同步 缺点：不同的值都需要一个单独的对象 复合优先与继承 在包内继承，是非常安全的 进行夸包边界的继承，是非常危险的 继承打破了封装性 只有子类真正是超累的子类型时 is-a，才试用继承 接口优与抽象类 java单继承，抽象类受到极大的限制 函数指针实现策略模式 Arrays.sort优先使用静态成员类 静态成员类、非静态成员类、匿名类、局部类 如果成员类不需要访问外围类实例，就使用静态成员类]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>
